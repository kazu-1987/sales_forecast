"""
é£²é£Ÿåº—å£²ä¸Šäºˆæ¸¬ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - Streamlitç‰ˆ
å®Ÿè¡Œæ–¹æ³•: streamlit run app.py
å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª: pip install streamlit pandas numpy scikit-learn plotly matplotlib seaborn
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error
import os
import pickle

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="é£²é£Ÿåº—å£²ä¸Šäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ´ é£²é£Ÿåº—å£²ä¸Šäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
st.sidebar.header("ğŸ“ ãƒ‡ãƒ¼ã‚¿ç®¡ç†")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data' not in st.session_state:
    st.session_state.data = None
if 'models' not in st.session_state:
    st.session_state.models = {}
if 'forecast_results' not in st.session_state:
    st.session_state.forecast_results = None

def load_and_process_data(uploaded_file):
    """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"""
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        data = pd.read_csv(uploaded_file, encoding='utf-8')
        
        # æ—¥ä»˜åˆ—ã‚’ datetime å‹ã«å¤‰æ›
        date_columns = ['æ—¥ä»˜', 'date', 'Date', 'DATE']
        for col in date_columns:
            if col in data.columns:
                data['date'] = pd.to_datetime(data[col])
                if col != 'date':
                    data = data.drop(col, axis=1)
                break
        
        # åˆ—åã‚’è‹±èªã«çµ±ä¸€
        column_mapping = {
            'åº—èˆ—': 'store',
            'åº—èˆ—å': 'store',
            'å£²ä¸Š': 'sales',
            'å£²ä¸Šé«˜': 'sales',
            'å£²ä¸Šå®Ÿç¸¾': 'sales',  # æ–°ã—ã„åˆ—åã«å¯¾å¿œ
            'å®¢æ•°': 'customers',
            'å®¢æ•°å®Ÿç¸¾': 'customers',  # æ–°ã—ã„åˆ—åã«å¯¾å¿œ
            'çµ„æ•°': 'groups',
            'åŠ´åƒæ™‚é–“': 'labor_hours',
            'äººæ™‚å£²ä¸Š': 'sales_per_hour',
            'æ›œæ—¥': 'weekday_jp',
            'ã‚¤ãƒ™ãƒ³ãƒˆ': 'event'
        }
        
        for jp_col, en_col in column_mapping.items():
            if jp_col in data.columns:
                data[en_col] = data[jp_col]
                if jp_col != en_col:
                    data = data.drop(jp_col, axis=1)
        
        # åº—èˆ—åãŒãªã„å ´åˆã®å‡¦ç†
        if 'store' not in data.columns:
            data['store'] = 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåº—èˆ—'
        
        # ã‚¤ãƒ™ãƒ³ãƒˆåˆ—ãŒãªã„å ´åˆã¯ç©ºæ–‡å­—ã§ä½œæˆ
        if 'event' not in data.columns:
            data['event'] = ''
        
        # ã‚¤ãƒ™ãƒ³ãƒˆåˆ—ã®NaNã‚’ç©ºæ–‡å­—ã«å¤‰æ›
        data['event'] = data['event'].fillna('')
        
        return data
        
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def create_features(data):
    """ç‰¹å¾´é‡ã‚’ä½œæˆ"""
    data = data.copy()
    
    # åŸºæœ¬çš„ãªæ™‚é–“ç‰¹å¾´é‡
    data['year'] = data['date'].dt.year
    data['month'] = data['date'].dt.month
    data['day'] = data['date'].dt.day
    data['dayofweek'] = data['date'].dt.dayofweek
    data['day_of_year'] = data['date'].dt.dayofyear
    data['week_of_year'] = data['date'].dt.isocalendar().week
    data['quarter'] = data['date'].dt.quarter
    data['is_weekend'] = (data['dayofweek'] >= 5).astype(int)
    data['is_month_start'] = data['date'].dt.is_month_start.astype(int)
    data['is_month_end'] = data['date'].dt.is_month_end.astype(int)
    
    # æ›œæ—¥ã”ã¨ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°ã‚’ä½œæˆï¼ˆåœŸæ—¥ã®å£²ä¸Šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ­£ç¢ºã«æ‰ãˆã‚‹ãŸã‚ï¼‰
    for i in range(7):
        data[f'is_weekday_{i}'] = (data['dayofweek'] == i).astype(int)
    
    # é‡‘æ›œæ—¥ã€åœŸæ›œæ—¥ã€æ—¥æ›œæ—¥ã®ç‰¹åˆ¥ãƒ•ãƒ©ã‚°
    data['is_friday'] = (data['dayofweek'] == 4).astype(int)
    data['is_saturday'] = (data['dayofweek'] == 5).astype(int)
    data['is_sunday'] = (data['dayofweek'] == 6).astype(int)
    
    # ã‚¤ãƒ™ãƒ³ãƒˆé–¢é€£ã®ç‰¹å¾´é‡ã‚’ä½œæˆ
    if 'event' in data.columns:
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆãŒã‚ã‚‹ã‹ã©ã†ã‹ï¼‰
        data['has_event'] = (data['event'] != '').astype(int)
        
        # ä¸»è¦ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒ€ãƒŸãƒ¼å¤‰æ•°ã‚’ä½œæˆ
        # ã‚¤ãƒ™ãƒ³ãƒˆåã‚’çµ±ä¸€ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã€ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç„¡è¦–ï¼‰
        data['event_normalized'] = data['event'].str.upper().str.replace(' ', '').str.replace('ã€€', '')
        
        # ä¸»è¦ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚«ãƒ†ã‚´ãƒª
        event_categories = {
            'year_end': ['å¹´æœ«å¹´å§‹', 'å¹´æœ«', 'å¹´å§‹', 'æ­£æœˆ', 'YEAREND', 'NEWYEAR'],
            'golden_week': ['ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¦ã‚£ãƒ¼ã‚¯', 'GW', 'GOLDENWEEK'],
            'obon': ['ãŠç›†', 'OBON', 'ç›†'],
            'holiday': ['ä¼‘æ¥­', 'ä¼‘ã¿', 'CLOSED', 'HOLIDAY'],
            'special_sale': ['ã‚»ãƒ¼ãƒ«', 'ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³', 'SALE', 'CAMPAIGN'],
            'event': ['ã‚¤ãƒ™ãƒ³ãƒˆ', 'EVENT', 'ç¥­ã‚Š', 'FESTIVAL']
        }
        
        # å„ã‚«ãƒ†ã‚´ãƒªã®ãƒ•ãƒ©ã‚°ã‚’ä½œæˆ
        for category, keywords in event_categories.items():
            data[f'event_{category}'] = 0
            for keyword in keywords:
                data.loc[data['event_normalized'].str.contains(keyword, na=False), f'event_{category}'] = 1
    
    # åº—èˆ—ã”ã¨ã®ç§»å‹•å¹³å‡ã¨æ›œæ—¥åˆ¥çµ±è¨ˆ
    for store in data['store'].unique():
        store_mask = data['store'] == store
        store_data = data[store_mask].sort_values('date')
        
        # 7æ—¥ç§»å‹•å¹³å‡
        data.loc[store_mask, 'sales_ma7'] = store_data['sales'].rolling(window=7, min_periods=1).mean()
        data.loc[store_mask, 'sales_ma30'] = store_data['sales'].rolling(window=30, min_periods=1).mean()
        
        # æ›œæ—¥åˆ¥ã®å£²ä¸Šçµ±è¨ˆã‚’ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ 
        weekday_stats = store_data.groupby('dayofweek')['sales'].agg(['mean', 'std', 'median'])
        for dow in range(7):
            if dow in weekday_stats.index:
                data.loc[store_mask & (data['dayofweek'] == dow), 'weekday_sales_mean'] = weekday_stats.loc[dow, 'mean']
                data.loc[store_mask & (data['dayofweek'] == dow), 'weekday_sales_std'] = weekday_stats.loc[dow, 'std']
            else:
                data.loc[store_mask & (data['dayofweek'] == dow), 'weekday_sales_mean'] = store_data['sales'].mean()
                data.loc[store_mask & (data['dayofweek'] == dow), 'weekday_sales_std'] = store_data['sales'].std()
        
        if 'customers' in data.columns:
            data.loc[store_mask, 'customers_ma7'] = store_data['customers'].rolling(window=7, min_periods=1).mean()
    
    return data

def train_model(store_data, store_name):
    """ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
    feature_columns = ['year', 'month', 'day', 'dayofweek', 'day_of_year', 
                      'week_of_year', 'quarter', 'is_weekend', 
                      'is_month_start', 'is_month_end',
                      'is_friday', 'is_saturday', 'is_sunday']
    
    # æ›œæ—¥ãƒ€ãƒŸãƒ¼å¤‰æ•°ã‚’è¿½åŠ 
    for i in range(7):
        feature_columns.append(f'is_weekday_{i}')
    
    # æ›œæ—¥åˆ¥çµ±è¨ˆç‰¹å¾´é‡ã‚’è¿½åŠ 
    if 'weekday_sales_mean' in store_data.columns:
        feature_columns.extend(['weekday_sales_mean', 'weekday_sales_std'])
    
    # ã‚¤ãƒ™ãƒ³ãƒˆé–¢é€£ã®ç‰¹å¾´é‡ã‚’è¿½åŠ 
    event_features = ['has_event', 'event_year_end', 'event_golden_week', 
                     'event_obon', 'event_holiday', 'event_special_sale', 'event_event']
    for col in event_features:
        if col in store_data.columns:
            feature_columns.append(col)
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ç‰¹å¾´é‡ã®è¿½åŠ 
    for col in ['customers', 'groups', 'labor_hours', 'sales_per_hour', 
                'sales_ma7', 'sales_ma30', 'customers_ma7']:
        if col in store_data.columns and not store_data[col].isna().all():
            feature_columns.append(col)
    
    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    store_data = store_data.sort_values('date')
    store_data = store_data.dropna(subset=['sales'] + [col for col in feature_columns if col in store_data.columns])
    
    # ä½¿ç”¨å¯èƒ½ãªç‰¹å¾´é‡ã®ã¿ã‚’é¸æŠ
    available_features = [col for col in feature_columns if col in store_data.columns]
    
    X = store_data[available_features]
    y = store_data['sales']
    
    # æ™‚ç³»åˆ—åˆ†å‰²
    split_index = int(len(X) * 0.8)
    X_train, X_test = X[:split_index], X[split_index:]
    y_train, y_test = y[:split_index], y[split_index:]
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ï¼‰
    from sklearn.ensemble import GradientBoostingRegressor
    
    # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ä»£ã‚ã‚Šã«å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚’è©¦ã™
    model = GradientBoostingRegressor(
        n_estimators=200,
        learning_rate=0.1,
        max_depth=5,
        min_samples_split=20,
        min_samples_leaf=10,
        subsample=0.8,
        random_state=42
    )
    
    # ä»£æ›¿æ¡ˆï¼šã‚ˆã‚Šæ·±ã„ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ
    # model = RandomForestRegressor(
    #     n_estimators=200,
    #     max_depth=15,
    #     min_samples_split=10,
    #     min_samples_leaf=5,
    #     random_state=42,
    #     n_jobs=-1
    # )
    
    model.fit(X_train, y_train)
    
    # è©•ä¾¡
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred) * 100
    r2 = r2_score(y_test, y_pred)
    
    # æ›œæ—¥åˆ¥ã®äºˆæ¸¬ç²¾åº¦ã‚’ç¢ºèª
    test_data = store_data.iloc[split_index:].copy()
    test_data['predicted'] = y_pred
    weekday_accuracy = test_data.groupby('dayofweek').agg({
        'sales': 'mean',
        'predicted': 'mean'
    })
    
    # çµæœã‚’ä¿å­˜
    result = {
        'model': model,
        'feature_columns': available_features,
        'mae': mae,
        'mape': mape,
        'r2': r2,
        'test_dates': store_data.iloc[split_index:]['date'].values,
        'test_actual': y_test.values,
        'test_pred': y_pred,
        'feature_importance': pd.DataFrame({
            'feature': available_features,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False),
        'event_impact': {},
        'weekday_accuracy': weekday_accuracy,
        'weekday_stats': store_data.groupby('dayofweek')['sales'].agg(['mean', 'std', 'count'])
    }
    
    # ã‚¤ãƒ™ãƒ³ãƒˆã®å½±éŸ¿ã‚’åˆ†æ
    if 'has_event' in available_features:
        event_data = store_data[store_data['has_event'] == 1]['sales'].mean()
        no_event_data = store_data[store_data['has_event'] == 0]['sales'].mean()
        if not pd.isna(event_data) and not pd.isna(no_event_data):
            result['event_impact']['overall'] = (event_data / no_event_data - 1) * 100
    
    return result

def make_forecast(model_info, store_data, days):
    """äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
    model = model_info['model']
    feature_columns = model_info['feature_columns']
    
    last_date = store_data['date'].max()
    last_row = store_data[store_data['date'] == last_date].iloc[0]
    
    # æ›œæ—¥åˆ¥ã®å£²ä¸Šçµ±è¨ˆã‚’å–å¾—
    weekday_stats = model_info.get('weekday_stats', store_data.groupby('dayofweek')['sales'].agg(['mean', 'std', 'count']))
    
    future_dates = []
    future_features = []
    
    for i in range(1, days + 1):
        future_date = last_date + timedelta(days=i)
        future_dates.append(future_date)
        
        # åŸºæœ¬ç‰¹å¾´é‡ã‚’ä½œæˆ
        features = {
            'year': future_date.year,
            'month': future_date.month,
            'day': future_date.day,
            'dayofweek': future_date.weekday(),
            'day_of_year': future_date.timetuple().tm_yday,
            'week_of_year': future_date.isocalendar().week,
            'quarter': (future_date.month - 1) // 3 + 1,
            'is_weekend': 1 if future_date.weekday() >= 5 else 0,
            'is_month_start': 1 if future_date.day == 1 else 0,
            'is_month_end': 1 if (future_date + timedelta(days=1)).day == 1 else 0,
            'is_friday': 1 if future_date.weekday() == 4 else 0,
            'is_saturday': 1 if future_date.weekday() == 5 else 0,
            'is_sunday': 1 if future_date.weekday() == 6 else 0
        }
        
        # æ›œæ—¥ãƒ€ãƒŸãƒ¼å¤‰æ•°
        for j in range(7):
            features[f'is_weekday_{j}'] = 1 if future_date.weekday() == j else 0
        
        # æ›œæ—¥åˆ¥çµ±è¨ˆç‰¹å¾´é‡
        dow = future_date.weekday()
        if 'weekday_sales_mean' in feature_columns:
            if dow in weekday_stats.index:
                features['weekday_sales_mean'] = weekday_stats.loc[dow, 'mean']
                features['weekday_sales_std'] = weekday_stats.loc[dow, 'std']
            else:
                features['weekday_sales_mean'] = store_data['sales'].mean()
                features['weekday_sales_std'] = store_data['sales'].std()
        
        # ã‚¤ãƒ™ãƒ³ãƒˆé–¢é€£ã®ç‰¹å¾´é‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯0ï¼‰
        event_features = ['has_event', 'event_year_end', 'event_golden_week', 
                         'event_obon', 'event_holiday', 'event_special_sale', 'event_event']
        for ef in event_features:
            if ef in feature_columns:
                features[ef] = 0
        
        # ãã®ä»–ã®ç‰¹å¾´é‡ã‚’è¿½åŠ 
        for col in feature_columns:
            if col not in features:
                if col in last_row.index and not pd.isna(last_row[col]):
                    features[col] = last_row[col]
                elif col in ['sales_ma7', 'sales_ma30']:
                    # ç§»å‹•å¹³å‡ã¯æœ€å¾Œã®å€¤ã‚’ä½¿ç”¨ï¼ˆNaNãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
                    if col in last_row.index and not pd.isna(last_row[col]):
                        features[col] = last_row[col]
                    else:
                        features[col] = store_data['sales'].tail(30).mean()
                elif col == 'customers_ma7':
                    if 'customers' in store_data.columns:
                        features[col] = store_data['customers'].tail(7).mean()
                    else:
                        features[col] = 0
                elif col in store_data.columns:
                    # ãã®ä»–ã®åˆ—ã¯å¹³å‡å€¤ã‚’ä½¿ç”¨
                    mean_val = store_data[col].mean()
                    features[col] = mean_val if not pd.isna(mean_val) else 0
                else:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                    features[col] = 0
        
        # NaNãƒã‚§ãƒƒã‚¯ã¨ç½®æ›
        feature_vector = []
        for col in feature_columns:
            val = features.get(col, 0)
            if pd.isna(val):
                val = 0
            feature_vector.append(val)
        
        future_features.append(feature_vector)
    
    # å£²ä¸Šäºˆæ¸¬
    predictions = model.predict(future_features)
    
    # çµæœã‚’DataFrameã«
    forecast_df = pd.DataFrame({
        'date': future_dates,
        'predicted_sales': predictions
    })
    
    # ä»–ã®æŒ‡æ¨™ã‚‚äºˆæ¸¬ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›¸é–¢ã‚’ä½¿ç”¨ï¼‰
    # å®¢æ•°äºˆæ¸¬
    if 'customers' in store_data.columns and 'sales' in store_data.columns:
        # å£²ä¸ŠãŒ0ã§ãªã„ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨
        valid_data = store_data[store_data['sales'] > 0]
        if len(valid_data) > 0:
            avg_customer_per_sale = (valid_data['customers'] / valid_data['sales']).mean()
            forecast_df['predicted_customers'] = (forecast_df['predicted_sales'] * avg_customer_per_sale).round().astype(int)
        else:
            forecast_df['predicted_customers'] = 0
    else:
        forecast_df['predicted_customers'] = 0
    
    # åŠ´åƒæ™‚é–“äºˆæ¸¬ï¼ˆæ›œæ—¥åˆ¥ã®å‚¾å‘ã‚’ä½¿ç”¨ï¼‰
    forecast_df['dayofweek'] = [d.weekday() for d in future_dates]
    
    # æ›œæ—¥åˆ¥ã®å£²ä¸Šã¨åŠ´åƒæ™‚é–“ã®é–¢ä¿‚ã‹ã‚‰æ¨å®š
    if 'labor_hours' in store_data.columns:
        weekday_labor = store_data.groupby('dayofweek')['labor_hours'].mean()
        forecast_df['predicted_labor_hours'] = forecast_df['dayofweek'].map(weekday_labor)
    else:
        # åŠ´åƒæ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã€å£²ä¸Šã«åŸºã¥ã„ã¦æ¨å®š
        base_hours = 80
        forecast_df['predicted_labor_hours'] = base_hours * (forecast_df['predicted_sales'] / store_data['sales'].mean())
    
    forecast_df['predicted_labor_hours'] = forecast_df['predicted_labor_hours'].fillna(85).round(1)
    
    # äººæ™‚å£²ä¸Šäºˆæ¸¬
    forecast_df['predicted_sales_per_hour'] = (forecast_df['predicted_sales'] / forecast_df['predicted_labor_hours']).round().astype(int)
    
    # ä¸è¦ãªåˆ—ã‚’å‰Šé™¤
    if 'dayofweek' in forecast_df.columns:
        forecast_df = forecast_df.drop('dayofweek', axis=1)
    
    return forecast_df

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# 1. ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.sidebar.file_uploader(
    "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=['csv'],
    help="æ—¥ä»˜ã€åº—èˆ—ã€å£²ä¸Šã€å®¢æ•°ã€çµ„æ•°ã€åŠ´åƒæ™‚é–“ã€äººæ™‚å£²ä¸Šãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«"
)

if uploaded_file is not None:
    # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    data = load_and_process_data(uploaded_file)
    
    if data is not None:
        # ç‰¹å¾´é‡ã‚’ä½œæˆ
        data = create_features(data)
        st.session_state.data = data
        
        # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã‚’è¡¨ç¤º
        st.sidebar.success(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(data):,}ä»¶")
        st.sidebar.info(f"ğŸ“… æœŸé–“: {data['date'].min().strftime('%Y-%m-%d')} ï½ {data['date'].max().strftime('%Y-%m-%d')}")
        st.sidebar.info(f"ğŸª åº—èˆ—æ•°: {data['store'].nunique()}åº—èˆ—")

# ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
if st.session_state.data is not None:
    data = st.session_state.data
    
    # ã‚¿ãƒ–ã‚’ä½œæˆ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦", "ğŸ¤– ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", "ğŸ”® å£²ä¸Šäºˆæ¸¬", "ğŸ“ˆ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ"])
    
    # ã‚¿ãƒ–1: ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    with tab1:
        st.header("ãƒ‡ãƒ¼ã‚¿æ¦‚è¦")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç·ãƒ‡ãƒ¼ã‚¿æ•°", f"{len(data):,}ä»¶")
        with col2:
            st.metric("åº—èˆ—æ•°", f"{data['store'].nunique()}åº—èˆ—")
        with col3:
            st.metric("ãƒ‡ãƒ¼ã‚¿æœŸé–“", f"{(data['date'].max() - data['date'].min()).days}æ—¥é–“")
        
        # åº—èˆ—é¸æŠ
        selected_store = st.selectbox("åº—èˆ—ã‚’é¸æŠ", data['store'].unique())
        store_data = data[data['store'] == selected_store]
        
        # å£²ä¸Šæ¨ç§»ã‚°ãƒ©ãƒ•
        st.subheader(f"{selected_store}ã®å£²ä¸Šæ¨ç§»")
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=store_data['date'],
            y=store_data['sales'],
            mode='lines',
            name='å£²ä¸Š',
            line=dict(color='blue', width=1)
        ))
        fig.update_layout(
            xaxis_title="æ—¥ä»˜",
            yaxis_title="å£²ä¸Šï¼ˆå††ï¼‰",
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        st.subheader("ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€æ–°10ä»¶ï¼‰")
        display_cols = ['date', 'sales', 'customers']
        if 'groups' in store_data.columns:
            display_cols.append('groups')
        if 'labor_hours' in store_data.columns:
            display_cols.append('labor_hours')
        if 'event' in store_data.columns:
            display_cols.append('event')
        
        st.dataframe(store_data.tail(10)[display_cols])
    
    # ã‚¿ãƒ–2: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    with tab2:
        st.header("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
        
        # å­¦ç¿’ã™ã‚‹åº—èˆ—ã‚’é¸æŠ
        stores_to_train = st.multiselect(
            "å­¦ç¿’ã™ã‚‹åº—èˆ—ã‚’é¸æŠ",
            data['store'].unique(),
            default=data['store'].unique()
        )
        
        if st.button("ğŸš€ ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’", type="primary"):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, store in enumerate(stores_to_train):
                status_text.text(f"å­¦ç¿’ä¸­: {store}")
                store_data = data[data['store'] == store]
                
                if len(store_data) >= 30:
                    model_info = train_model(store_data, store)
                    st.session_state.models[store] = model_info
                    
                    # çµæœã‚’è¡¨ç¤º
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(f"{store} - MAE", f"Â¥{model_info['mae']:,.0f}")
                    with col2:
                        st.metric(f"{store} - MAPE", f"{model_info['mape']:.1f}%")
                    with col3:
                        st.metric(f"{store} - RÂ²", f"{model_info['r2']:.3f}")
                    
                    # æ›œæ—¥åˆ¥ç²¾åº¦ã‚’è¡¨ç¤º
                    if 'weekday_accuracy' in model_info:
                        with st.expander(f"{store} ã®æ›œæ—¥åˆ¥äºˆæ¸¬ç²¾åº¦"):
                            weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
                            accuracy_df = model_info['weekday_accuracy'].copy()
                            accuracy_df.index = [weekday_names[i] for i in accuracy_df.index]
                            accuracy_df.columns = ['å®Ÿç¸¾å¹³å‡', 'äºˆæ¸¬å¹³å‡']
                            accuracy_df['å·®ç•°(%)'] = ((accuracy_df['äºˆæ¸¬å¹³å‡'] / accuracy_df['å®Ÿç¸¾å¹³å‡'] - 1) * 100).round(1)
                            st.dataframe(accuracy_df)
                    
                    # æ›œæ—¥åˆ¥ç²¾åº¦ã‚’è¡¨ç¤º
                    if 'weekday_accuracy' in model_info:
                        with st.expander(f"{store} ã®æ›œæ—¥åˆ¥äºˆæ¸¬ç²¾åº¦"):
                            weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
                            accuracy_df = model_info['weekday_accuracy'].copy()
                            accuracy_df.index = [weekday_names[i] for i in accuracy_df.index]
                            accuracy_df.columns = ['å®Ÿç¸¾å¹³å‡', 'äºˆæ¸¬å¹³å‡']
                            accuracy_df['å·®ç•°(%)'] = ((accuracy_df['äºˆæ¸¬å¹³å‡'] / accuracy_df['å®Ÿç¸¾å¹³å‡'] - 1) * 100).round(1)
                            st.dataframe(accuracy_df)
                    with col1:
                        st.metric(f"{store} - MAE", f"Â¥{model_info['mae']:,.0f}")
                    with col2:
                        st.metric(f"{store} - MAPE", f"{model_info['mape']:.1f}%")
                    with col3:
                        st.metric(f"{store} - RÂ²", f"{model_info['r2']:.3f}")
                else:
                    st.warning(f"{store}ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(store_data)}ä»¶ï¼‰")
                
                progress_bar.progress((i + 1) / len(stores_to_train))
            
            status_text.text("âœ… å­¦ç¿’å®Œäº†ï¼")
        
        # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±
        if st.session_state.models:
            st.subheader("å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«")
            model_summary = []
            for store, info in st.session_state.models.items():
                model_summary.append({
                    'åº—èˆ—': store,
                    'MAE': f"Â¥{info['mae']:,.0f}",
                    'MAPE': f"{info['mape']:.1f}%",
                    'RÂ²': f"{info['r2']:.3f}"
                })
            st.dataframe(pd.DataFrame(model_summary))
    
    # ã‚¿ãƒ–3: å£²ä¸Šäºˆæ¸¬
    with tab3:
        st.header("å£²ä¸Šäºˆæ¸¬")
        
        if not st.session_state.models:
            st.warning("âš ï¸ ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")
        else:
            col1, col2 = st.columns(2)
            with col1:
                forecast_store = st.selectbox(
                    "äºˆæ¸¬ã™ã‚‹åº—èˆ—",
                    list(st.session_state.models.keys())
                )
            with col2:
                forecast_days = st.slider("äºˆæ¸¬æ—¥æ•°", 7, 90, 30)
            
            if st.button("ğŸ“ˆ äºˆæ¸¬å®Ÿè¡Œ", type="primary"):
                # äºˆæ¸¬ã‚’å®Ÿè¡Œ
                store_data = data[data['store'] == forecast_store]
                model_info = st.session_state.models[forecast_store]
                forecast_df = make_forecast(model_info, store_data, forecast_days)
                
                # çµæœã‚’ä¿å­˜
                st.session_state.forecast_results = {
                    'store': forecast_store,
                    'forecast': forecast_df
                }
                
                # äºˆæ¸¬çµæœã®ã‚µãƒãƒªãƒ¼
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("äºˆæ¸¬æœŸé–“åˆè¨ˆå£²ä¸Š", f"Â¥{forecast_df['predicted_sales'].sum():,.0f}")
                with col2:
                    st.metric("æ—¥æ¬¡å¹³å‡å£²ä¸Š", f"Â¥{forecast_df['predicted_sales'].mean():,.0f}")
                with col3:
                    st.metric("æœŸé–“ä¸­ã®å¹³å‡äººæ™‚å£²ä¸Š", f"Â¥{forecast_df['predicted_sales_per_hour'].mean():,.0f}")
                
                # ã‚°ãƒ©ãƒ•è¡¨ç¤º
                st.subheader("å£²ä¸Šäºˆæ¸¬ã‚°ãƒ©ãƒ•")
                
                # å®Ÿç¸¾ã¨äºˆæ¸¬ã‚’çµåˆã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ
                recent_actual = store_data.tail(60)
                
                fig = go.Figure()
                
                # å®Ÿç¸¾
                fig.add_trace(go.Scatter(
                    x=recent_actual['date'],
                    y=recent_actual['sales'],
                    mode='lines+markers',
                    name='å®Ÿç¸¾å£²ä¸Š',
                    line=dict(color='blue', width=2),
                    marker=dict(size=4)
                ))
                
                # äºˆæ¸¬
                fig.add_trace(go.Scatter(
                    x=forecast_df['date'],
                    y=forecast_df['predicted_sales'],
                    mode='lines+markers',
                    name='äºˆæ¸¬å£²ä¸Š',
                    line=dict(color='red', width=2, dash='dash'),
                    marker=dict(size=4)
                ))
                
                fig.update_layout(
                    xaxis_title="æ—¥ä»˜",
                    yaxis_title="å£²ä¸Šï¼ˆå††ï¼‰",
                    height=500,
                    hovermode='x unified'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # æ—¥æ¯ã®è©³ç´°äºˆæ¸¬è¡¨ç¤º
                st.subheader("æ—¥æ¯äºˆæ¸¬è©³ç´°")
                
                # è¡¨ç¤ºç”¨ã®DataFrameã‚’ä½œæˆ
                display_df = forecast_df.copy()
                
                # æ›œæ—¥åã‚’è¿½åŠ 
                weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
                display_df['æ›œæ—¥'] = display_df['date'].dt.dayofweek.apply(lambda x: weekday_names[x])
                
                # æ—¥ä»˜ã‚’æ›œæ—¥ä»˜ãã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                display_df['æ—¥ä»˜'] = display_df['date'].dt.strftime('%Y-%m-%d') + ' (' + display_df['æ›œæ—¥'] + ')'
                display_df['åº—èˆ—'] = forecast_store
                display_df['äºˆæ¸¬å£²ä¸Š'] = display_df['predicted_sales'].apply(lambda x: f"Â¥{x:,.0f}")
                display_df['äºˆæ¸¬å®¢æ•°'] = display_df['predicted_customers']
                display_df['äºˆæ¸¬åŠ´åƒæ™‚é–“'] = display_df['predicted_labor_hours']
                display_df['äºˆæ¸¬äººæ™‚'] = display_df['predicted_sales_per_hour'].apply(lambda x: f"Â¥{x:,.0f}")
                
                # æŒ‡å®šã•ã‚ŒãŸé †ç•ªã§è¡¨ç¤º
                display_columns = ['æ—¥ä»˜', 'åº—èˆ—', 'äºˆæ¸¬å£²ä¸Š', 'äºˆæ¸¬å®¢æ•°', 'äºˆæ¸¬åŠ´åƒæ™‚é–“', 'äºˆæ¸¬äººæ™‚']
                display_df = display_df[display_columns]
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤ºï¼ˆã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ï¼‰
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    height=400
                )
                
                # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ã®DataFrameã‚’ä½œæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‰ã®æ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼‰
                export_df = forecast_df.copy()
                weekday_names_export = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
                export_df['æ›œæ—¥'] = export_df['date'].dt.dayofweek.apply(lambda x: weekday_names_export[x])
                export_df['æ—¥ä»˜'] = export_df['date'].dt.strftime('%Y-%m-%d')
                export_df['åº—èˆ—'] = forecast_store
                export_df = export_df.rename(columns={
                    'predicted_sales': 'äºˆæ¸¬å£²ä¸Š',
                    'predicted_customers': 'äºˆæ¸¬å®¢æ•°',
                    'predicted_labor_hours': 'äºˆæ¸¬åŠ´åƒæ™‚é–“',
                    'predicted_sales_per_hour': 'äºˆæ¸¬äººæ™‚'
                })
                export_df = export_df[['æ—¥ä»˜', 'æ›œæ—¥', 'åº—èˆ—', 'äºˆæ¸¬å£²ä¸Š', 'äºˆæ¸¬å®¢æ•°', 'äºˆæ¸¬åŠ´åƒæ™‚é–“', 'äºˆæ¸¬äººæ™‚']]
                
                csv = export_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name=f'{forecast_store}_forecast_{datetime.now().strftime("%Y%m%d")}.csv',
                    mime='text/csv'
                )
    
    # ã‚¿ãƒ–4: åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
    with tab4:
        st.header("åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        
        if st.session_state.models:
            # ç‰¹å¾´é‡é‡è¦åº¦
            st.subheader("ç‰¹å¾´é‡ã®é‡è¦åº¦")
            
            selected_store_report = st.selectbox(
                "åˆ†æã™ã‚‹åº—èˆ—",
                list(st.session_state.models.keys()),
                key="report_store"
            )
            
            model_info = st.session_state.models[selected_store_report]
            importance_df = model_info['feature_importance'].head(10)
            
            fig = px.bar(
                importance_df,
                x='importance',
                y='feature',
                orientation='h',
                title=f"{selected_store_report}ã®ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½10ï¼‰"
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # å…¨åº—èˆ—æ¯”è¼ƒ
            st.subheader("å…¨åº—èˆ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ")
            
            comparison_data = []
            for store, info in st.session_state.models.items():
                comparison_data.append({
                    'åº—èˆ—': store,
                    'MAE': info['mae'],
                    'MAPE': info['mape'],
                    'RÂ²': info['r2']
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            
            # MAPEã§ã‚½ãƒ¼ãƒˆã—ã¦æ£’ã‚°ãƒ©ãƒ•
            comparison_df = comparison_df.sort_values('MAPE')
            
            fig = px.bar(
                comparison_df,
                x='åº—èˆ—',
                y='MAPE',
                title="åº—èˆ—åˆ¥äºˆæ¸¬ç²¾åº¦ï¼ˆMAPE: ä½ã„ã»ã©è‰¯ã„ï¼‰",
                color='MAPE',
                color_continuous_scale='RdYlGn_r'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            st.subheader("ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜")
            if st.button("ğŸ’¾ å…¨ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"):
                # ãƒ¢ãƒ‡ãƒ«ã‚’pickleã§ä¿å­˜
                with open('sales_forecast_models.pkl', 'wb') as f:
                    pickle.dump(st.session_state.models, f)
                st.success("âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆsales_forecast_models.pklï¼‰")

else:
    # ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆ
    st.info("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª¬æ˜
    st.subheader("å¿…è¦ãªãƒ‡ãƒ¼ã‚¿å½¢å¼")
    st.markdown("""
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ã®åˆ—ãŒå¿…è¦ã§ã™ï¼š
    - **æ—¥ä»˜**: å£²ä¸Šæ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
    - **åº—èˆ—**: åº—èˆ—å
    - **å£²ä¸Šå®Ÿç¸¾** ã¾ãŸã¯ **å£²ä¸Š**: å£²ä¸Šé‡‘é¡
    - **å®¢æ•°å®Ÿç¸¾** ã¾ãŸã¯ **å®¢æ•°**: æ¥åº—å®¢æ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    - **ã‚¤ãƒ™ãƒ³ãƒˆ**: ã‚¤ãƒ™ãƒ³ãƒˆåï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    â€» ãã®ä»–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³åˆ—ï¼šçµ„æ•°ã€åŠ´åƒæ™‚é–“ã€äººæ™‚å£²ä¸Š
    """)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    sample_data = pd.DataFrame({
        'æ—¥ä»˜': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-12-31'],
        'åº—èˆ—': ['æ¸‹è°·åº—', 'æ¸‹è°·åº—', 'æ¸‹è°·åº—', 'æ¸‹è°·åº—'],
        'å£²ä¸Šå®Ÿç¸¾': [150000, 180000, 165000, 250000],
        'å®¢æ•°å®Ÿç¸¾': [150, 180, 165, 300],
        'ã‚¤ãƒ™ãƒ³ãƒˆ': ['å¹´æœ«å¹´å§‹', '', '', 'å¹´æœ«å¹´å§‹']
    })
    st.dataframe(sample_data)