"""
é£²é£Ÿåº—å£²ä¸Šäºˆæ¸¬ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - Prophetç‰ˆ
å®Ÿè¡Œæ–¹æ³•: streamlit run app_prophet.py
å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª: pip install streamlit pandas numpy prophet plotly matplotlib
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from prophet import Prophet
from prophet.plot import plot_plotly, plot_components_plotly
import warnings
warnings.filterwarnings('ignore')

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="é£²é£Ÿåº—å£²ä¸Šäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - Prophetç‰ˆ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ´ é£²é£Ÿåº—å£²ä¸Šäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  (Prophetç‰ˆ)")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
st.sidebar.header("ğŸ“ ãƒ‡ãƒ¼ã‚¿ç®¡ç†")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data' not in st.session_state:
    st.session_state.data = None
if 'models' not in st.session_state:
    st.session_state.models = {}
if 'forecast_results' not in st.session_state:
    st.session_state.forecast_results = None

def load_and_process_data(uploaded_file):
    """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"""
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        data = pd.read_csv(uploaded_file, encoding='utf-8')
        
        # æ—¥ä»˜åˆ—ã‚’ datetime å‹ã«å¤‰æ›
        date_columns = ['æ—¥ä»˜', 'date', 'Date', 'DATE']
        for col in date_columns:
            if col in data.columns:
                data['date'] = pd.to_datetime(data[col])
                if col != 'date':
                    data = data.drop(col, axis=1)
                break
        
        # åˆ—åã‚’è‹±èªã«çµ±ä¸€
        column_mapping = {
            'åº—èˆ—': 'store',
            'åº—èˆ—å': 'store',
            'å£²ä¸Š': 'sales',
            'å£²ä¸Šé«˜': 'sales',
            'å£²ä¸Šå®Ÿç¸¾': 'sales',
            'å®¢æ•°': 'customers',
            'å®¢æ•°å®Ÿç¸¾': 'customers',
            'çµ„æ•°': 'groups',
            'åŠ´åƒæ™‚é–“': 'labor_hours',
            'äººæ™‚å£²ä¸Š': 'sales_per_hour',
            'æ›œæ—¥': 'weekday_jp',
            'ã‚¤ãƒ™ãƒ³ãƒˆ': 'event'
        }
        
        for jp_col, en_col in column_mapping.items():
            if jp_col in data.columns:
                data[en_col] = data[jp_col]
                if jp_col != en_col:
                    data = data.drop(jp_col, axis=1)
        
        # åº—èˆ—åãŒãªã„å ´åˆã®å‡¦ç†
        if 'store' not in data.columns:
            data['store'] = 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåº—èˆ—'
        
        # ã‚¤ãƒ™ãƒ³ãƒˆåˆ—ãŒãªã„å ´åˆã¯ç©ºæ–‡å­—ã§ä½œæˆ
        if 'event' not in data.columns:
            data['event'] = ''
        
        # ã‚¤ãƒ™ãƒ³ãƒˆåˆ—ã®NaNã‚’ç©ºæ–‡å­—ã«å¤‰æ›
        data['event'] = data['event'].fillna('')
        
        return data
        
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def prepare_prophet_data(store_data, include_regressors=True):
    """Prophetç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™"""
    # Prophetå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    prophet_df = pd.DataFrame({
        'ds': store_data['date'],
        'y': store_data['sales']
    })
    
    # å¤–ã‚Œå€¤ã®å‡¦ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    # 3Ïƒã‚’è¶…ãˆã‚‹å€¤ã‚’capã¨floorã§åˆ¶é™
    mean_sales = prophet_df['y'].mean()
    std_sales = prophet_df['y'].std()
    prophet_df['cap'] = mean_sales + 3 * std_sales
    prophet_df['floor'] = max(0, mean_sales - 3 * std_sales)
    
    if include_regressors:
        # è¿½åŠ ã®å›å¸°å¤‰æ•°ã‚’æº–å‚™
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒ©ã‚°
        if 'event' in store_data.columns:
            prophet_df['has_event'] = (store_data['event'] != '').astype(int)
            
            # ä¸»è¦ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒ€ãƒŸãƒ¼å¤‰æ•°
            prophet_df['is_year_end'] = store_data['event'].str.contains('å¹´æœ«å¹´å§‹|å¹´æœ«|å¹´å§‹', na=False).astype(int)
            prophet_df['is_golden_week'] = store_data['event'].str.contains('ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¦ã‚£ãƒ¼ã‚¯|GW', na=False).astype(int)
            prophet_df['is_obon'] = store_data['event'].str.contains('ãŠç›†|ç›†', na=False).astype(int)
            prophet_df['is_holiday'] = store_data['event'].str.contains('ä¼‘æ¥­|ä¼‘ã¿', na=False).astype(int)
        
        # å®¢æ•°ï¼ˆã‚ã‚Œã°ï¼‰
        if 'customers' in store_data.columns:
            prophet_df['customers'] = store_data['customers']
    
    return prophet_df

def train_prophet_model(prophet_df, store_name):
    """Prophetãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
    # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    model = Prophet(
        growth='linear',  # or 'logistic'
        changepoint_prior_scale=0.05,  # ãƒˆãƒ¬ãƒ³ãƒ‰ã®æŸ”è»Ÿæ€§
        seasonality_prior_scale=10.0,  # å­£ç¯€æ€§ã®å¼·ã•
        holidays_prior_scale=10.0,  # ç¥æ—¥åŠ¹æœã®å¼·ã•
        seasonality_mode='multiplicative',  # ä¹—æ³•çš„å­£ç¯€æ€§
        interval_width=0.95,  # äºˆæ¸¬åŒºé–“
        daily_seasonality=False,
        weekly_seasonality=True,
        yearly_seasonality=True
    )
    
    # æ—¥æœ¬ã®ç¥æ—¥ã‚’è¿½åŠ ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    holidays = pd.DataFrame({
        'holiday': 'japanese_holiday',
        'ds': pd.to_datetime([
            '2022-01-01', '2022-01-02', '2022-01-03', '2022-05-03', '2022-05-04', '2022-05-05',
            '2023-01-01', '2023-01-02', '2023-01-03', '2023-05-03', '2023-05-04', '2023-05-05',
            '2024-01-01', '2024-01-02', '2024-01-03', '2024-05-03', '2024-05-04', '2024-05-05',
            '2025-01-01', '2025-01-02', '2025-01-03', '2025-05-03', '2025-05-04', '2025-05-05'
        ])
    })
    model.holidays = holidays
    
    # å›å¸°å¤‰æ•°ã®è¿½åŠ 
    if 'has_event' in prophet_df.columns:
        model.add_regressor('has_event')
    if 'is_year_end' in prophet_df.columns:
        model.add_regressor('is_year_end')
    if 'is_golden_week' in prophet_df.columns:
        model.add_regressor('is_golden_week')
    if 'is_obon' in prophet_df.columns:
        model.add_regressor('is_obon')
    
    # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
    model.fit(prophet_df)
    
    # æ¤œè¨¼ç”¨ã®äºˆæ¸¬
    # æœ€å¾Œã®20%ã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨
    split_index = int(len(prophet_df) * 0.8)
    train_df = prophet_df[:split_index]
    test_df = prophet_df[split_index:]
    
    # è©•ä¾¡æŒ‡æ¨™ã®åˆæœŸåŒ–
    mae = 0
    mape = 0
    rmse = 0
    r2 = 0
    weekday_accuracy = pd.DataFrame()
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æœŸé–“ã®äºˆæ¸¬ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«ã‚ã‚‹å ´åˆã®ã¿ï¼‰
    if len(test_df) > 7:  # æœ€ä½1é€±é–“åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
        try:
            # å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            future_all = model.make_future_dataframe(periods=0)
            
            # å›å¸°å¤‰æ•°ã‚’è¿½åŠ 
            for col in ['has_event', 'is_year_end', 'is_golden_week', 'is_obon']:
                if col in prophet_df.columns:
                    future_all = future_all.merge(
                        prophet_df[['ds', col]], 
                        on='ds', 
                        how='left'
                    ).fillna(0)
            
            # äºˆæ¸¬å®Ÿè¡Œ
            forecast_all = model.predict(future_all)
            
            # ãƒ†ã‚¹ãƒˆæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            test_forecast = forecast_all[forecast_all['ds'].isin(test_df['ds'])].copy()
            test_actual = test_df.merge(test_forecast[['ds', 'yhat']], on='ds', how='left')
            
            # ç²¾åº¦è©•ä¾¡
            actual = test_actual['y'].values
            predicted = test_actual['yhat'].values
            
            # NaNã‚’é™¤å¤–
            mask = ~(np.isnan(actual) | np.isnan(predicted))
            actual = actual[mask]
            predicted = predicted[mask]
            
            if len(actual) > 0:
                mae = np.mean(np.abs(actual - predicted))
                mape = np.mean(np.abs((actual - predicted) / (actual + 1))) * 100  # +1ã§0é™¤ç®—ã‚’é˜²ã
                rmse = np.sqrt(np.mean((actual - predicted) ** 2))
                
                # RÂ²ã‚¹ã‚³ã‚¢
                if len(actual) > 1:
                    from sklearn.metrics import r2_score
                    r2 = r2_score(actual, predicted)
                
                # æ›œæ—¥åˆ¥ç²¾åº¦
                test_actual['dayofweek'] = pd.to_datetime(test_actual['ds']).dt.dayofweek
                weekday_accuracy = test_actual.groupby('dayofweek').agg({
                    'y': 'mean',
                    'yhat': 'mean'
                }).rename(columns={'yhat': 'predicted'})
        except Exception as e:
            st.warning(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    return {
        'model': model,
        'mae': mae,
        'mape': mape,
        'rmse': rmse,
        'r2': r2,
        'weekday_accuracy': weekday_accuracy,
        'prophet_df': prophet_df
    }

def make_prophet_forecast(model_info, store_data, total_days):
    """Prophetã«ã‚ˆã‚‹äºˆæ¸¬ï¼ˆéå»æœŸé–“ã‚‚å«ã‚€ï¼‰"""
    model = model_info['model']
    prophet_df = model_info['prophet_df']
    
    # å°†æ¥ã®æ—¥ä»˜ã‚’ä½œæˆï¼ˆéå»ã®ãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã¦å…¨æœŸé–“ã‚’ã‚«ãƒãƒ¼ï¼‰
    # Prophetã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã‹ã‚‰äºˆæ¸¬ã™ã‚‹ãŸã‚ã€make_future_dataframeã§å…¨æœŸé–“ã‚’ç”Ÿæˆ
    future = model.make_future_dataframe(periods=total_days, freq='D', include_history=True)
    
    # å°†æ¥ã®å›å¸°å¤‰æ•°ã‚’è¨­å®š
    for col in ['has_event', 'is_year_end', 'is_golden_week', 'is_obon']:
        if col in prophet_df.columns:
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å›å¸°å¤‰æ•°ã‚’å–å¾—
            existing_values = prophet_df[['ds', col]]
            future = future.merge(existing_values, on='ds', how='left')
            # å°†æ¥ã®å€¤ã¯0ã§åŸ‹ã‚ã‚‹
            future[col] = future[col].fillna(0)
    
    # äºˆæ¸¬å®Ÿè¡Œ
    forecast = model.predict(future)
    
    # çµæœã‚’æ•´å½¢
    forecast_df = pd.DataFrame({
        'date': forecast['ds'],
        'predicted_sales': forecast['yhat'],
        'lower_bound': forecast['yhat_lower'],
        'upper_bound': forecast['yhat_upper']
    })
    
    # å®¢æ•°äºˆæ¸¬
    if 'customers' in store_data.columns and 'sales' in store_data.columns:
        valid_data = store_data[store_data['sales'] > 0]
        if len(valid_data) > 0:
            avg_customer_per_sale = (valid_data['customers'] / valid_data['sales']).mean()
            forecast_df['predicted_customers'] = (forecast_df['predicted_sales'] * avg_customer_per_sale).round().astype(int)
        else:
            forecast_df['predicted_customers'] = 0
    else:
        forecast_df['predicted_customers'] = 0
    
    # åŠ´åƒæ™‚é–“äºˆæ¸¬
    forecast_df['dayofweek'] = forecast_df['date'].dt.dayofweek
    if 'labor_hours' in store_data.columns:
        weekday_labor = store_data.groupby(store_data['date'].dt.dayofweek)['labor_hours'].mean()
        forecast_df['predicted_labor_hours'] = forecast_df['dayofweek'].map(weekday_labor)
    else:
        base_hours = 80
        forecast_df['predicted_labor_hours'] = base_hours * (forecast_df['predicted_sales'] / store_data['sales'].mean())
    
    forecast_df['predicted_labor_hours'] = forecast_df['predicted_labor_hours'].fillna(85).round(1)
    
    # äººæ™‚å£²ä¸Šäºˆæ¸¬
    forecast_df['predicted_sales_per_hour'] = (forecast_df['predicted_sales'] / forecast_df['predicted_labor_hours']).round().astype(int)
    
    # ä¸è¦ãªåˆ—ã‚’å‰Šé™¤
    forecast_df = forecast_df.drop('dayofweek', axis=1)
    
    return forecast_df, forecast

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# 1. ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.sidebar.file_uploader(
    "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=['csv'],
    help="æ—¥ä»˜ã€åº—èˆ—ã€å£²ä¸Šã€å®¢æ•°ã€ã‚¤ãƒ™ãƒ³ãƒˆãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«"
)

if uploaded_file is not None:
    # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    data = load_and_process_data(uploaded_file)
    
    if data is not None:
        st.session_state.data = data
        
        # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã‚’è¡¨ç¤º
        st.sidebar.success(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(data):,}ä»¶")
        st.sidebar.info(f"ğŸ“… æœŸé–“: {data['date'].min().strftime('%Y-%m-%d')} ï½ {data['date'].max().strftime('%Y-%m-%d')}")
        st.sidebar.info(f"ğŸª åº—èˆ—æ•°: {data['store'].nunique()}åº—èˆ—")

# ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
if st.session_state.data is not None:
    data = st.session_state.data
    
    # ã‚¿ãƒ–ã‚’ä½œæˆ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦", "ğŸ¤– ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", "ğŸ”® å£²ä¸Šäºˆæ¸¬", "ğŸ“ˆ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ"])
    
    # ã‚¿ãƒ–1: ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    with tab1:
        st.header("ãƒ‡ãƒ¼ã‚¿æ¦‚è¦")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç·ãƒ‡ãƒ¼ã‚¿æ•°", f"{len(data):,}ä»¶")
        with col2:
            st.metric("åº—èˆ—æ•°", f"{data['store'].nunique()}åº—èˆ—")
        with col3:
            st.metric("ãƒ‡ãƒ¼ã‚¿æœŸé–“", f"{(data['date'].max() - data['date'].min()).days}æ—¥é–“")
        
        # åº—èˆ—é¸æŠ
        selected_store = st.selectbox("åº—èˆ—ã‚’é¸æŠ", data['store'].unique())
        store_data = data[data['store'] == selected_store]
        
        # å£²ä¸Šæ¨ç§»ã‚°ãƒ©ãƒ•
        st.subheader(f"{selected_store}ã®å£²ä¸Šæ¨ç§»")
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=store_data['date'],
            y=store_data['sales'],
            mode='lines',
            name='å£²ä¸Š',
            line=dict(color='blue', width=1)
        ))
        fig.update_layout(
            xaxis_title="æ—¥ä»˜",
            yaxis_title="å£²ä¸Šï¼ˆå††ï¼‰",
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        st.subheader("ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€æ–°10ä»¶ï¼‰")
        display_cols = ['date', 'sales']
        if 'customers' in store_data.columns:
            display_cols.append('customers')
        if 'event' in store_data.columns:
            display_cols.append('event')
        
        st.dataframe(store_data.tail(10)[display_cols])
    
    # ã‚¿ãƒ–2: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    with tab2:
        st.header("Prophetãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
        
        # å­¦ç¿’ã™ã‚‹åº—èˆ—ã‚’é¸æŠ
        stores_to_train = st.multiselect(
            "å­¦ç¿’ã™ã‚‹åº—èˆ—ã‚’é¸æŠ",
            data['store'].unique(),
            default=data['store'].unique()
        )
        
        # é«˜åº¦ãªè¨­å®š
        with st.expander("ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆä¸Šç´šè€…å‘ã‘ï¼‰"):
            col1, col2 = st.columns(2)
            with col1:
                changepoint_prior_scale = st.slider(
                    "ãƒˆãƒ¬ãƒ³ãƒ‰ã®æŸ”è»Ÿæ€§",
                    0.001, 0.5, 0.05,
                    help="å¤§ãã„ã»ã©ãƒˆãƒ¬ãƒ³ãƒ‰ãŒæŸ”è»Ÿã«å¤‰åŒ–"
                )
                seasonality_prior_scale = st.slider(
                    "å­£ç¯€æ€§ã®å¼·ã•",
                    0.01, 25.0, 10.0,
                    help="å¤§ãã„ã»ã©å­£ç¯€æ€§ãŒå¼·ãåæ˜ "
                )
            with col2:
                seasonality_mode = st.selectbox(
                    "å­£ç¯€æ€§ãƒ¢ãƒ¼ãƒ‰",
                    ['multiplicative', 'additive'],
                    help="multiplicative: å£²ä¸Šã«æ¯”ä¾‹ã€additive: ä¸€å®šé¡"
                )
                include_regressors = st.checkbox(
                    "ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚’ä½¿ç”¨",
                    value=True
                )
        
        if st.button("ğŸš€ ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’", type="primary"):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, store in enumerate(stores_to_train):
                status_text.text(f"å­¦ç¿’ä¸­: {store}")
                store_data = data[data['store'] == store]
                
                if len(store_data) >= 30:
                    # Prophetç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
                    prophet_df = prepare_prophet_data(store_data, include_regressors)
                    
                    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
                    model_info = train_prophet_model(prophet_df, store)
                    st.session_state.models[store] = model_info
                    
                    # çµæœã‚’è¡¨ç¤º
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        if model_info['mae'] > 0:
                            st.metric(f"{store} - MAE", f"Â¥{model_info['mae']:,.0f}")
                        else:
                            st.metric(f"{store} - MAE", "è©•ä¾¡ä¸­...")
                    with col2:
                        if model_info['mape'] > 0:
                            st.metric(f"{store} - MAPE", f"{model_info['mape']:.1f}%")
                        else:
                            st.metric(f"{store} - MAPE", "è©•ä¾¡ä¸­...")
                    with col3:
                        if model_info['rmse'] > 0:
                            st.metric(f"{store} - RMSE", f"Â¥{model_info['rmse']:,.0f}")
                        else:
                            st.metric(f"{store} - RMSE", "è©•ä¾¡ä¸­...")
                    with col4:
                        if model_info['r2'] > 0:
                            st.metric(f"{store} - RÂ²", f"{model_info['r2']:.3f}")
                        else:
                            st.metric(f"{store} - RÂ²", "è©•ä¾¡ä¸­...")
                    
                    # æ›œæ—¥åˆ¥ç²¾åº¦ã‚’è¡¨ç¤º
                    if len(model_info['weekday_accuracy']) > 0:
                        with st.expander(f"{store} ã®æ›œæ—¥åˆ¥äºˆæ¸¬ç²¾åº¦"):
                            weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
                            accuracy_df = model_info['weekday_accuracy'].copy()
                            if len(accuracy_df) > 0:
                                accuracy_df.index = [weekday_names[i] for i in accuracy_df.index if i < len(weekday_names)]
                                accuracy_df.columns = ['å®Ÿç¸¾å¹³å‡', 'äºˆæ¸¬å¹³å‡']
                                accuracy_df['å·®ç•°(%)'] = ((accuracy_df['äºˆæ¸¬å¹³å‡'] / accuracy_df['å®Ÿç¸¾å¹³å‡'] - 1) * 100).round(1)
                                st.dataframe(accuracy_df)
                else:
                    st.warning(f"{store}ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(store_data)}ä»¶ï¼‰")
                
                progress_bar.progress((i + 1) / len(stores_to_train))
            
            status_text.text("âœ… å…¨ã¦ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    # ã‚¿ãƒ–3: å£²ä¸Šäºˆæ¸¬
    with tab3:
        st.header("å£²ä¸Šäºˆæ¸¬")
        
        if not st.session_state.models:
            st.warning("âš ï¸ ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")
        else:
            col1, col2, col3 = st.columns(3)
            with col1:
                forecast_store = st.selectbox(
                    "äºˆæ¸¬ã™ã‚‹åº—èˆ—",
                    list(st.session_state.models.keys())
                )
            
            # äºˆæ¸¬æœŸé–“ã®é¸æŠï¼ˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å¼ï¼‰
            store_data = data[data['store'] == forecast_store]
            first_date = store_data['date'].min().date()
            last_date = store_data['date'].max().date()
            
            with col2:
                start_date = st.date_input(
                    "äºˆæ¸¬é–‹å§‹æ—¥",
                    value=last_date + timedelta(days=1),
                    min_value=first_date,
                    max_value=last_date + timedelta(days=365),
                    help="éå»ã®æ—¥ä»˜ã‚’é¸æŠã™ã‚‹ã¨ã€å®Ÿç¸¾ã¨ã®æ¯”è¼ƒãŒå¯èƒ½ã§ã™"
                )
            
            with col3:
                default_end = min(start_date + timedelta(days=29), last_date + timedelta(days=60))
                end_date = st.date_input(
                    "äºˆæ¸¬çµ‚äº†æ—¥",
                    value=default_end,
                    min_value=start_date,
                    max_value=start_date + timedelta(days=365),
                    help="é–‹å§‹æ—¥ã‹ã‚‰æœ€å¤§365æ—¥å…ˆã¾ã§é¸æŠå¯èƒ½"
                )
            
            # äºˆæ¸¬æ—¥æ•°ã‚’è¨ˆç®—
            forecast_days = (end_date - start_date).days + 1
            
            # éå»ãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒæƒ…å ±
            if start_date <= last_date:
                overlap_days = min(end_date, last_date) - start_date + timedelta(days=1)
                st.info(f"ğŸ“Š äºˆæ¸¬æœŸé–“: {start_date} ï½ {end_date} ({forecast_days}æ—¥é–“)")
                if overlap_days.days > 0:
                    st.success(f"âœ… {overlap_days.days}æ—¥åˆ†ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒå¯èƒ½ã§ã™")
            else:
                st.info(f"ğŸ”® äºˆæ¸¬æœŸé–“: {start_date} ï½ {end_date} ({forecast_days}æ—¥é–“)")
            
            if forecast_days > 365:
                st.error("äºˆæ¸¬æœŸé–“ã¯æœ€å¤§365æ—¥ã¾ã§ã§ã™")
            elif forecast_days <= 0:
                st.error("äºˆæ¸¬æœŸé–“ã‚’æ­£ã—ãè¨­å®šã—ã¦ãã ã•ã„")
            
            if st.button("ğŸ“ˆ äºˆæ¸¬å®Ÿè¡Œ", type="primary") and 0 < forecast_days <= 365:
                # äºˆæ¸¬ã‚’å®Ÿè¡Œ
                model_info = st.session_state.models[forecast_store]
                
                # Prophetã®äºˆæ¸¬æœŸé–“ã‚’è¨ˆç®—ï¼ˆãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã‹ã‚‰äºˆæ¸¬çµ‚äº†æ—¥ã¾ã§ï¼‰
                days_from_start = (end_date - first_date).days + 1
                
                # äºˆæ¸¬å®Ÿè¡Œ
                forecast_df, full_forecast = make_prophet_forecast(model_info, store_data, days_from_start)
                
                # æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æŠ½å‡º
                forecast_df = forecast_df[
                    (forecast_df['date'].dt.date >= start_date) & 
                    (forecast_df['date'].dt.date <= end_date)
                ].copy()
                
                # çµæœã‚’ä¿å­˜
                st.session_state.forecast_results = {
                    'store': forecast_store,
                    'forecast': forecast_df,
                    'full_forecast': full_forecast,
                    'start_date': start_date,
                    'end_date': end_date
                }
                
                # äºˆæ¸¬çµæœã®ã‚µãƒãƒªãƒ¼
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("äºˆæ¸¬æœŸé–“åˆè¨ˆå£²ä¸Š", f"Â¥{forecast_df['predicted_sales'].sum():,.0f}")
                with col2:
                    st.metric("æ—¥æ¬¡å¹³å‡å£²ä¸Š", f"Â¥{forecast_df['predicted_sales'].mean():,.0f}")
                with col3:
                    st.metric("æœŸé–“ä¸­ã®å¹³å‡äººæ™‚å£²ä¸Š", f"Â¥{forecast_df['predicted_sales_per_hour'].mean():,.0f}")
                
                # å®Ÿç¸¾ã¨ã®æ¯”è¼ƒï¼ˆéå»æœŸé–“ãŒå«ã¾ã‚Œã‚‹å ´åˆï¼‰
                if start_date <= last_date:
                    actual_data = store_data[
                        (store_data['date'].dt.date >= start_date) & 
                        (store_data['date'].dt.date <= min(end_date, last_date))
                    ]
                    
                    if len(actual_data) > 0:
                        # å®Ÿç¸¾ã¨äºˆæ¸¬ã®æ¯”è¼ƒã‚°ãƒ©ãƒ•
                        st.subheader("å®Ÿç¸¾ã¨äºˆæ¸¬ã®æ¯”è¼ƒ")
                        
                        fig = go.Figure()
                        
                        # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿
                        fig.add_trace(go.Scatter(
                            x=actual_data['date'],
                            y=actual_data['sales'],
                            mode='lines+markers',
                            name='å®Ÿç¸¾',
                            line=dict(color='blue', width=2)
                        ))
                        
                        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿç¸¾æœŸé–“ã®ã¿ï¼‰
                        forecast_overlap = forecast_df[forecast_df['date'].dt.date <= last_date]
                        if len(forecast_overlap) > 0:
                            fig.add_trace(go.Scatter(
                                x=forecast_overlap['date'],
                                y=forecast_overlap['predicted_sales'],
                                mode='lines+markers',
                                name='äºˆæ¸¬',
                                line=dict(color='red', width=2, dash='dash')
                            ))
                            
                            # äºˆæ¸¬åŒºé–“
                            fig.add_trace(go.Scatter(
                                x=forecast_overlap['date'],
                                y=forecast_overlap['upper_bound'],
                                fill=None,
                                mode='lines',
                                line_color='rgba(255,0,0,0)',
                                showlegend=False
                            ))
                            
                            fig.add_trace(go.Scatter(
                                x=forecast_overlap['date'],
                                y=forecast_overlap['lower_bound'],
                                fill='tonexty',
                                mode='lines',
                                line_color='rgba(255,0,0,0)',
                                name='äºˆæ¸¬åŒºé–“',
                                fillcolor='rgba(255,0,0,0.2)'
                            ))
                        
                        fig.update_layout(
                            xaxis_title="æ—¥ä»˜",
                            yaxis_title="å£²ä¸Šï¼ˆå††ï¼‰",
                            height=400
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # ç²¾åº¦è©•ä¾¡
                        if len(forecast_overlap) > 0:
                            merged_data = actual_data.merge(
                                forecast_overlap[['date', 'predicted_sales']], 
                                on='date', 
                                how='inner'
                            )
                            
                            if len(merged_data) > 0:
                                mae = np.mean(np.abs(merged_data['sales'] - merged_data['predicted_sales']))
                                mape = np.mean(np.abs((merged_data['sales'] - merged_data['predicted_sales']) / merged_data['sales'])) * 100
                                
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.metric("æ¯”è¼ƒæœŸé–“ã®MAE", f"Â¥{mae:,.0f}")
                                with col2:
                                    st.metric("æ¯”è¼ƒæœŸé–“ã®MAPE", f"{mape:.1f}%")
                
                # Prophetã®ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆå…¨æœŸé–“ï¼‰
                st.subheader("å£²ä¸Šäºˆæ¸¬ã‚°ãƒ©ãƒ•ï¼ˆå…¨æœŸé–“ï¼‰")
                fig = plot_plotly(model_info['model'], full_forecast)
                st.plotly_chart(fig, use_container_width=True)
                
                # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆ†è§£
                st.subheader("äºˆæ¸¬ã®æ§‹æˆè¦ç´ ")
                fig_components = plot_components_plotly(model_info['model'], full_forecast)
                st.plotly_chart(fig_components, use_container_width=True)
                
                # æ—¥æ¯ã®è©³ç´°äºˆæ¸¬è¡¨ç¤º
                st.subheader("æ—¥æ¯äºˆæ¸¬è©³ç´°")
                
                # è¡¨ç¤ºç”¨ã®DataFrameã‚’ä½œæˆ
                display_df = forecast_df.copy()
                
                # æ›œæ—¥åã‚’è¿½åŠ 
                weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
                display_df['æ›œæ—¥'] = display_df['date'].dt.dayofweek.apply(lambda x: weekday_names[x])
                
                # æ—¥ä»˜ã‚’æ›œæ—¥ä»˜ãã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                display_df['æ—¥ä»˜'] = display_df['date'].dt.strftime('%Y-%m-%d') + ' (' + display_df['æ›œæ—¥'] + ')'
                display_df['åº—èˆ—'] = forecast_store
                display_df['äºˆæ¸¬å£²ä¸Š'] = display_df['predicted_sales'].apply(lambda x: f"Â¥{x:,.0f}")
                display_df['äºˆæ¸¬å®¢æ•°'] = display_df['predicted_customers']
                display_df['äºˆæ¸¬åŠ´åƒæ™‚é–“'] = display_df['predicted_labor_hours']
                display_df['äºˆæ¸¬äººæ™‚'] = display_df['predicted_sales_per_hour'].apply(lambda x: f"Â¥{x:,.0f}")
                
                # äºˆæ¸¬åŒºé–“ã‚‚è¡¨ç¤º
                display_df['äºˆæ¸¬åŒºé–“'] = display_df.apply(
                    lambda row: f"Â¥{row['lower_bound']:,.0f} ~ Â¥{row['upper_bound']:,.0f}",
                    axis=1
                )
                
                # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
                if start_date <= last_date:
                    actual_for_display = store_data[
                        (store_data['date'].dt.date >= start_date) & 
                        (store_data['date'].dt.date <= end_date)
                    ][['date', 'sales']].copy()
                    
                    if len(actual_for_display) > 0:
                        display_df = display_df.merge(
                            actual_for_display.rename(columns={'sales': 'actual_sales'}),
                            on='date',
                            how='left'
                        )
                        display_df['å®Ÿç¸¾å£²ä¸Š'] = display_df['actual_sales'].apply(
                            lambda x: f"Â¥{x:,.0f}" if pd.notna(x) else "-"
                        )
                        display_columns = ['æ—¥ä»˜', 'åº—èˆ—', 'å®Ÿç¸¾å£²ä¸Š', 'äºˆæ¸¬å£²ä¸Š', 'äºˆæ¸¬å®¢æ•°', 'äºˆæ¸¬åŠ´åƒæ™‚é–“', 'äºˆæ¸¬äººæ™‚', 'äºˆæ¸¬åŒºé–“']
                    else:
                        display_columns = ['æ—¥ä»˜', 'åº—èˆ—', 'äºˆæ¸¬å£²ä¸Š', 'äºˆæ¸¬å®¢æ•°', 'äºˆæ¸¬åŠ´åƒæ™‚é–“', 'äºˆæ¸¬äººæ™‚', 'äºˆæ¸¬åŒºé–“']
                else:
                    display_columns = ['æ—¥ä»˜', 'åº—èˆ—', 'äºˆæ¸¬å£²ä¸Š', 'äºˆæ¸¬å®¢æ•°', 'äºˆæ¸¬åŠ´åƒæ™‚é–“', 'äºˆæ¸¬äººæ™‚', 'äºˆæ¸¬åŒºé–“']
                
                display_df = display_df[display_columns]
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤ºï¼ˆã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ï¼‰
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    height=400
                )
                
                # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                
                export_df = forecast_df.copy()
                weekday_names_export = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
                export_df['æ›œæ—¥'] = export_df['date'].dt.dayofweek.apply(lambda x: weekday_names_export[x])
                export_df['æ—¥ä»˜'] = export_df['date'].dt.strftime('%Y-%m-%d')
                export_df['åº—èˆ—'] = forecast_store
                export_df = export_df.rename(columns={
                    'predicted_sales': 'äºˆæ¸¬å£²ä¸Š',
                    'predicted_customers': 'äºˆæ¸¬å®¢æ•°',
                    'predicted_labor_hours': 'äºˆæ¸¬åŠ´åƒæ™‚é–“',
                    'predicted_sales_per_hour': 'äºˆæ¸¬äººæ™‚',
                    'lower_bound': 'äºˆæ¸¬ä¸‹é™',
                    'upper_bound': 'äºˆæ¸¬ä¸Šé™'
                })
                
                # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã‚‹ï¼ˆã‚ã‚Œã°ï¼‰
                if start_date <= last_date:
                    actual_export = store_data[
                        (store_data['date'].dt.date >= start_date) & 
                        (store_data['date'].dt.date <= end_date)
                    ][['date', 'sales']].copy()
                    
                    if len(actual_export) > 0:
                        export_df = export_df.merge(
                            actual_export.rename(columns={'sales': 'å®Ÿç¸¾å£²ä¸Š'}),
                            on='date',
                            how='left'
                        )
                        export_df = export_df[['æ—¥ä»˜', 'æ›œæ—¥', 'åº—èˆ—', 'å®Ÿç¸¾å£²ä¸Š', 'äºˆæ¸¬å£²ä¸Š', 'äºˆæ¸¬å®¢æ•°', 'äºˆæ¸¬åŠ´åƒæ™‚é–“', 'äºˆæ¸¬äººæ™‚', 'äºˆæ¸¬ä¸‹é™', 'äºˆæ¸¬ä¸Šé™']]
                    else:
                        export_df = export_df[['æ—¥ä»˜', 'æ›œæ—¥', 'åº—èˆ—', 'äºˆæ¸¬å£²ä¸Š', 'äºˆæ¸¬å®¢æ•°', 'äºˆæ¸¬åŠ´åƒæ™‚é–“', 'äºˆæ¸¬äººæ™‚', 'äºˆæ¸¬ä¸‹é™', 'äºˆæ¸¬ä¸Šé™']]
                else:
                    export_df = export_df[['æ—¥ä»˜', 'æ›œæ—¥', 'åº—èˆ—', 'äºˆæ¸¬å£²ä¸Š', 'äºˆæ¸¬å®¢æ•°', 'äºˆæ¸¬åŠ´åƒæ™‚é–“', 'äºˆæ¸¬äººæ™‚', 'äºˆæ¸¬ä¸‹é™', 'äºˆæ¸¬ä¸Šé™']]
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                col1, col2 = st.columns(2)
                
                with col1:
                    # UTF-8 BOMä»˜ãï¼ˆExcelå¯¾å¿œï¼‰
                    csv_utf8 = export_df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Excel/Macå¯¾å¿œ)",
                        data=csv_utf8,
                        file_name=f'{forecast_store}_prophet_forecast_{datetime.now().strftime("%Y%m%d")}_utf8.csv',
                        mime='text/csv',
                        help="UTF-8 BOMä»˜ãå½¢å¼ã€‚Excelã€Numbersã€Google Sheetsã§æ–‡å­—åŒ–ã‘ã›ãšã«é–‹ã‘ã¾ã™"
                    )
                
                with col2:
                    # Shift-JISï¼ˆWindows Excelç”¨ï¼‰
                    try:
                        csv_sjis = export_df.to_csv(index=False, encoding='shift-jis')
                        st.download_button(
                            label="ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Windowså°‚ç”¨)",
                            data=csv_sjis,
                            file_name=f'{forecast_store}_prophet_forecast_{datetime.now().strftime("%Y%m%d")}_sjis.csv',
                            mime='text/csv',
                            help="Shift-JISå½¢å¼ã€‚å¤ã„Windows Excelã§é–‹ãå ´åˆã«ä½¿ç”¨"
                        )
                    except:
                        st.info("Shift-JISå¤‰æ›ã‚¨ãƒ©ãƒ¼ã€‚UTF-8ç‰ˆã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")
    
    # ã‚¿ãƒ–4: åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
    with tab4:
        st.header("åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        
        if st.session_state.models:
            # å…¨åº—èˆ—ã®äºˆæ¸¬ç²¾åº¦æ¯”è¼ƒ
            st.subheader("åº—èˆ—åˆ¥äºˆæ¸¬ç²¾åº¦")
            
            comparison_data = []
            for store, info in st.session_state.models.items():
                data_row = {'åº—èˆ—': store}
                if info['mae'] > 0:
                    data_row['MAE'] = info['mae']
                    data_row['MAPE'] = info['mape']
                    data_row['RMSE'] = info['rmse']
                    data_row['RÂ²'] = info['r2']
                else:
                    data_row['MAE'] = None
                    data_row['MAPE'] = None
                    data_row['RMSE'] = None
                    data_row['RÂ²'] = None
                comparison_data.append(data_row)
            
            if comparison_data:
                comparison_df = pd.DataFrame(comparison_data)
                
                # NaNã‚’é™¤å¤–ã—ã¦ã‚°ãƒ©ãƒ•ä½œæˆ
                valid_df = comparison_df.dropna(subset=['MAPE'])
                
                if len(valid_df) > 0:
                    # MAPEã§ã‚½ãƒ¼ãƒˆã—ã¦æ£’ã‚°ãƒ©ãƒ•
                    valid_df = valid_df.sort_values('MAPE')
                    
                    fig = px.bar(
                        valid_df,
                        x='åº—èˆ—',
                        y='MAPE',
                        title="åº—èˆ—åˆ¥äºˆæ¸¬ç²¾åº¦ï¼ˆMAPE: ä½ã„ã»ã©è‰¯ã„ï¼‰",
                        color='MAPE',
                        color_continuous_scale='RdYlGn_r'
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # è©³ç´°ãªè©•ä¾¡æŒ‡æ¨™ãƒ†ãƒ¼ãƒ–ãƒ«
                    st.subheader("è©•ä¾¡æŒ‡æ¨™è©³ç´°")
                    display_df = valid_df.copy()
                    display_df['MAE'] = display_df['MAE'].apply(lambda x: f"Â¥{x:,.0f}" if pd.notna(x) else "-")
                    display_df['MAPE'] = display_df['MAPE'].apply(lambda x: f"{x:.1f}%" if pd.notna(x) else "-")
                    display_df['RMSE'] = display_df['RMSE'].apply(lambda x: f"Â¥{x:,.0f}" if pd.notna(x) else "-")
                    display_df['RÂ²'] = display_df['RÂ²'].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "-")
                    st.dataframe(display_df)
                else:
                    st.info("è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ä¸­ã§ã™ã€‚ååˆ†ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                comparison_df = comparison_df.sort_values('MAPE')
                
                fig = px.bar(
                    comparison_df,
                    x='åº—èˆ—',
                    y='MAPE',
                    title="åº—èˆ—åˆ¥äºˆæ¸¬ç²¾åº¦ï¼ˆMAPE: ä½ã„ã»ã©è‰¯ã„ï¼‰",
                    color='MAPE',
                    color_continuous_scale='RdYlGn_r'
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            # Prophetãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´
            st.subheader("Prophetãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´")
            st.markdown("""
            **Prophetã®åˆ©ç‚¹:**
            - ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è‡ªå‹•çš„ã«æ¤œå‡ºãƒ»äºˆæ¸¬
            - ğŸ“… é€±æ¬¡ãƒ»å¹´æ¬¡ã®å­£ç¯€æ€§ã‚’è‡ªå‹•ãƒ¢ãƒ‡ãƒ«åŒ–
            - ğŸŒ ç¥æ—¥åŠ¹æœã‚’è€ƒæ…®å¯èƒ½
            - ğŸ“Š äºˆæ¸¬åŒºé–“ï¼ˆä¿¡é ¼åŒºé–“ï¼‰ã‚’æä¾›
            - ğŸ”§ æ¬ æå€¤ã‚„å¤–ã‚Œå€¤ã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆ
            
            **é©ç”¨ã‚·ãƒ¼ãƒ³:**
            - é•·æœŸçš„ãªãƒˆãƒ¬ãƒ³ãƒ‰ãŒã‚ã‚‹ãƒ‡ãƒ¼ã‚¿
            - æ˜ç¢ºãªå­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹ãƒ‡ãƒ¼ã‚¿
            - ç¥æ—¥ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã®å½±éŸ¿ãŒå¤§ãã„ãƒ“ã‚¸ãƒã‚¹
            """)

else:
    # ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆ
    st.info("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª¬æ˜
    st.subheader("å¿…è¦ãªãƒ‡ãƒ¼ã‚¿å½¢å¼")
    st.markdown("""
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ã®åˆ—ãŒå¿…è¦ã§ã™ï¼š
    - **æ—¥ä»˜**: å£²ä¸Šæ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
    - **åº—èˆ—**: åº—èˆ—å
    - **å£²ä¸Šå®Ÿç¸¾** ã¾ãŸã¯ **å£²ä¸Š**: å£²ä¸Šé‡‘é¡
    - **å®¢æ•°å®Ÿç¸¾** ã¾ãŸã¯ **å®¢æ•°**: æ¥åº—å®¢æ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    - **ã‚¤ãƒ™ãƒ³ãƒˆ**: ã‚¤ãƒ™ãƒ³ãƒˆåï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    â€» Prophetã¯æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«ç‰¹åŒ–ã—ã¦ã„ã‚‹ãŸã‚ã€æ—¥ä»˜ã¨å£²ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°åŸºæœ¬çš„ãªäºˆæ¸¬ãŒå¯èƒ½ã§ã™ã€‚
    """)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    sample_data = pd.DataFrame({
        'æ—¥ä»˜': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-12-31'],
        'åº—èˆ—': ['æ¸‹è°·åº—', 'æ¸‹è°·åº—', 'æ¸‹è°·åº—', 'æ¸‹è°·åº—'],
        'å£²ä¸Šå®Ÿç¸¾': [150000, 180000, 165000, 250000],
        'å®¢æ•°å®Ÿç¸¾': [150, 180, 165, 300],
        'ã‚¤ãƒ™ãƒ³ãƒˆ': ['å¹´æœ«å¹´å§‹', '', '', 'å¹´æœ«å¹´å§‹']
    })
    st.dataframe(sample_data)